#!/usr/bin/env python3
"""
Migration script to convert from user-ID-based storage to anonymous content-addressable storage.

This script:
1. Scans all existing user directories
2. Computes content hashes for all files
3. Moves files to new anonymous storage structure
4. Creates ownership records in database
5. Cleans up old directory structure

Usage:
    python3 migrate_to_anonymous_storage.py [--dry-run] [--backup]
"""

import os
import sys
import hashlib
import shutil
import logging
from pathlib import Path
from datetime import datetime
import argparse

# Add parent directory to path to import app modules
sys.path.insert(0, os.path.dirname(__file__))

from db_adapter import create_database_adapter

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def compute_file_hash(file_path):
    """Compute SHA-256 hash of a file."""
    sha256 = hashlib.sha256()
    with open(file_path, 'rb') as f:
        while True:
            chunk = f.read(8192)
            if not chunk:
                break
            sha256.update(chunk)
    return sha256.hexdigest()


def get_anonymous_storage_path(data_dir, file_hash):
    """Get the new storage path for a file based on its hash."""
    storage_dir = data_dir / 'files'
    shard_dir = storage_dir / file_hash[:2]
    return shard_dir / file_hash


def migrate_user_directory(account_number, user_dir, data_dir, db_adapter, dry_run=False, stats=None):
    """Migrate all files from a user directory to anonymous storage."""
    if not user_dir.is_dir():
        return
    
    file_count = 0
    migrated_count = 0
    error_count = 0
    
    account_secret = str(account_number)
    account_id = hashlib.sha256(account_secret.encode('utf-8')).hexdigest()
    account_fingerprint = account_id[:12]

    if not dry_run:
        try:
            db_adapter.insert_one({
                "account_id": account_id,
                "created_at": datetime.utcnow()
            })
            logger.info(f"Provisioned account fingerprint={account_fingerprint} from legacy account {account_number}")
        except ValueError:
            logger.info(f"Account fingerprint={account_fingerprint} already exists; reusing existing record")
        except Exception as exc:
            logger.warning(f"Failed to upsert account fingerprint={account_fingerprint}: {exc}")
    
    logger.info(f"Migrating account {account_number} (fingerprint={account_fingerprint})...")
    
    for file_path in user_dir.iterdir():
        if not file_path.is_file():
            continue
        
        file_count += 1
        
        try:
            # Compute hash of encrypted file
            logger.info(f"  Processing: {file_path.name}")
            file_hash = compute_file_hash(file_path)
            file_size = file_path.stat().st_size
            
            # Get new storage location
            new_path = get_anonymous_storage_path(data_dir, file_hash)
            
            if not dry_run:
                # Create shard directory
                new_path.parent.mkdir(parents=True, exist_ok=True)
                
                # Copy file to new location (use copy, not move, to be safe)
                if not new_path.exists():
                    shutil.copy2(file_path, new_path)
                    logger.info(f"    → Copied to {new_path}")
                else:
                    logger.info(f"    → Already exists at {new_path} (deduplication)")
                
                # Create ownership record
                # Note: encrypted_metadata would need to be generated by client
                # For migration, we use a placeholder that indicates migration
                encrypted_metadata = f"MIGRATED_FROM_{file_path.name}"
                
                try:
                    db_adapter.add_file_ownership(
                        account_id=account_id,
                        file_hash=file_hash,
                        encrypted_metadata=encrypted_metadata,
                        file_size=file_size
                    )
                    logger.info(f"    → Ownership record created")
                except Exception as e:
                    logger.warning(f"    → Ownership record may already exist: {e}")
            else:
                logger.info(f"    → [DRY RUN] Would copy to {new_path}")
                logger.info(f"    → [DRY RUN] Would create ownership record")
            
            migrated_count += 1
            
        except Exception as e:
            logger.error(f"  Error migrating {file_path}: {e}")
            error_count += 1
    
    if stats is not None:
        stats['total_files'] += file_count
        stats['migrated'] += migrated_count
        stats['errors'] += error_count
    
    logger.info(f"Account {account_number} (fingerprint={account_fingerprint}): {migrated_count}/{file_count} files migrated, {error_count} errors")


def backup_directory(source_dir, backup_dir):
    """Create a backup of the source directory."""
    logger.info(f"Creating backup: {source_dir} → {backup_dir}")
    try:
        shutil.copytree(source_dir, backup_dir, dirs_exist_ok=False)
        logger.info(f"Backup created successfully")
        return True
    except Exception as e:
        logger.error(f"Backup failed: {e}")
        return False


def cleanup_old_structure(data_dir, dry_run=False):
    """Remove old user directories after successful migration."""
    logger.info("Cleaning up old directory structure...")
    
    for item in data_dir.iterdir():
        if item.is_dir() and item.name != 'files' and item.name.isdigit():
            # This looks like an old user directory
            if dry_run:
                logger.info(f"  [DRY RUN] Would remove: {item}")
            else:
                try:
                    shutil.rmtree(item)
                    logger.info(f"  Removed: {item}")
                except Exception as e:
                    logger.error(f"  Failed to remove {item}: {e}")


def main():
    parser = argparse.ArgumentParser(description='Migrate to anonymous storage')
    parser.add_argument('--dry-run', action='store_true', 
                       help='Show what would be done without making changes')
    parser.add_argument('--backup', action='store_true',
                       help='Create a backup before migrating')
    parser.add_argument('--no-cleanup', action='store_true',
                       help='Do not clean up old directories after migration')
    parser.add_argument('--data-dir', type=str, default='./data',
                       help='Path to data directory (default: ./data)')
    
    args = parser.parse_args()
    
    data_dir = Path(args.data_dir)
    
    if not data_dir.exists():
        logger.error(f"Data directory not found: {data_dir}")
        return 1
    
    logger.info("=" * 60)
    logger.info("Anonymous Storage Migration Tool")
    logger.info("=" * 60)
    logger.info(f"Data directory: {data_dir}")
    logger.info(f"Dry run: {args.dry_run}")
    logger.info(f"Backup: {args.backup}")
    logger.info("")
    
    # Create backup if requested
    if args.backup and not args.dry_run:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_dir = data_dir.parent / f"data_backup_{timestamp}"
        if not backup_directory(data_dir, backup_dir):
            logger.error("Backup failed, aborting migration")
            return 1
        logger.info("")
    
    # Initialize database
    try:
        db_adapter = create_database_adapter()
        logger.info("Database connection established")
        logger.info("")
    except Exception as e:
        logger.error(f"Failed to connect to database: {e}")
        return 1
    
    # Statistics
    stats = {
        'total_files': 0,
        'migrated': 0,
        'errors': 0,
        'accounts': 0
    }
    
    # Scan for user directories (numeric directory names)
    logger.info("Scanning for user directories...")
    user_dirs = []
    for item in data_dir.iterdir():
        if item.is_dir() and item.name.isdigit():
            account_number = int(item.name)
            user_dirs.append((account_number, item))
    
    logger.info(f"Found {len(user_dirs)} user directories")
    logger.info("")
    
    # Migrate each user directory
    for account_number, user_dir in sorted(user_dirs):
        stats['accounts'] += 1
        migrate_user_directory(account_number, user_dir, data_dir, db_adapter, args.dry_run, stats)
        logger.info("")
    
    # Clean up old structure if requested
    if not args.no_cleanup and not args.dry_run:
        cleanup_old_structure(data_dir, args.dry_run)
    
    # Print summary
    logger.info("=" * 60)
    logger.info("Migration Summary")
    logger.info("=" * 60)
    logger.info(f"Accounts processed: {stats['accounts']}")
    logger.info(f"Total files: {stats['total_files']}")
    logger.info(f"Successfully migrated: {stats['migrated']}")
    logger.info(f"Errors: {stats['errors']}")
    logger.info("")
    
    if args.dry_run:
        logger.info("This was a dry run. No changes were made.")
        logger.info("Run without --dry-run to perform the actual migration.")
    else:
        logger.info("Migration complete!")
        logger.info("")
        logger.info("IMPORTANT NOTES:")
        logger.info("1. Users will need to rebuild their file indexes")
        logger.info("2. Encrypted metadata shows 'MIGRATED_FROM_*' - users should re-upload for proper metadata")
        logger.info("3. Test the application thoroughly before removing backups")
    
    return 0 if stats['errors'] == 0 else 1


if __name__ == '__main__':
    sys.exit(main())
